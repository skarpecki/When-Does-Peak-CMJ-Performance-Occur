{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1bdf9fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import power_divergence, binomtest\n",
    "import polars as pl\n",
    "from matplotlib.lines import Line2D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b99e316",
   "metadata": {},
   "source": [
    "## Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3b26885d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR        = \"./data\"\n",
    "SRC_PATH        = f\"{DATA_DIR}/00_src\" # Remember to have this data generated from Hawkin Dynamics SDK\n",
    "COMBINED_PATH   = f\"{DATA_DIR}/01_raw/01_combined.csv\"\n",
    "PURE_CMJ_PATH   = f\"{DATA_DIR}/01_raw/02_combined_cmj.csv\"\n",
    "PLOTS_DIR       = f\"{DATA_DIR}/plots\"\n",
    "STATS_DIR       = f\"{DATA_DIR}/metric_stats\"\n",
    "LOG_PATH        = f\"{DATA_DIR}/pipeline_stats.log\"\n",
    "\n",
    "CMJ_TEST_TYPE   = \"Countermovement Jump\"\n",
    "\n",
    "ATHLETES_TO_DROP = [\n",
    "    \"test test\",\n",
    "    \"test walidacja imu\",\n",
    "    \"test 1\",\n",
    "    \"test 2\",\n",
    "    \"test 3\",\n",
    "    \"test 4\",\n",
    "    \"test 5\",\n",
    "    \"test 6\",\n",
    "    \"Zawodnik 1\",\n",
    "    \"Zawodnik 2\",\n",
    "    \"Matt Jordan\",\n",
    "    \"Matt Jordan 2\",\n",
    "    \"Matt Jordan 4\",\n",
    "    \"Matt Jordan 5\",\n",
    "]\n",
    "\n",
    "COLUMNS_TO_DROP = [\n",
    "    \"athlete_id\",\n",
    "    \"external_kl6xI7wHgSTNtCNyjJpYWHYOmmn1\",\n",
    "    \"testType_id\",\n",
    "    \"testType_canonicalId\",\n",
    "    \"tag_ids\",\n",
    "    \"athlete_teams\",\n",
    "    \"athlete_groups\",\n",
    "    \"active\",\n",
    "    \"athlete_active\",\n",
    "]\n",
    "\n",
    "MIN_FAMILIARIZATION_DAYS    = 1\n",
    "MIN_REPS_IN_FAM_SESSION     = 3\n",
    "MIN_REPS_IN_VALID_SESSION   = 6\n",
    "KEEP_FIRST_N = 6\n",
    "REST_THRESHOLD_SEC = 30\n",
    "\n",
    "METRICS_CONFIG = [\n",
    "    (\"jump_height_m\",                       \"JH\"),\n",
    "    (\"mrsi\",                                \"mRSI\"),\n",
    "    (\"stiffness_n_m\",                       \"Stiffness\"),\n",
    "    (\"avg_relative_braking_force\",          \"ARBF\"),\n",
    "    (\"avg_relative_braking_power_w_kg\",     \"ARBP\"),\n",
    "    (\"avg_relative_propulsive_force\",       \"ARPF\"),\n",
    "    (\"avg_relative_propulsive_power_w_kg\",  \"ARPP\"),\n",
    "]\n",
    "\n",
    "G_ACC = 9.80665\n",
    "\n",
    "TECHNICAL_COLUMNS = [\n",
    "    \"id\", \"athlete_name\", \"timestamp\", \"test_datetime\",\n",
    "    \"test_date\", \"session_number\", \"rep_number\",\n",
    "    \"rest_before_rep_seconds\", \"testType_name\", \n",
    "    \"system_weight_n\", \"system_weight_kg\"\n",
    "]\n",
    "\n",
    "METRICS_COLUMNS = [\n",
    "    \"jump_height_m\", \"mrsi\", \"stiffness_n_m\", \"avg_relative_braking_force\",\n",
    "    \"avg_relative_braking_power_w_kg\", \"avg_relative_propulsive_force\",\n",
    "    \"avg_relative_propulsive_power_w_kg\",\n",
    "]\n",
    "\n",
    "SIGMA_THRESHOLD = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28856ddf",
   "metadata": {},
   "source": [
    "## Pipeline technical functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0facc89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensure_dir(path: str) -> None:\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "\n",
    "\n",
    "def log_stats(stage: str, df: pl.DataFrame, log_path: str) -> None:\n",
    "    first_date = df.select(pl.col(\"test_date\").min()).item()\n",
    "    last_date = df.select(pl.col(\"test_date\").max()).item()\n",
    "    rep_count = df.select(pl.col(\"id\").len()).item()\n",
    "    athlete_count = df.select(pl.col(\"athlete_name\").n_unique()).item()\n",
    "    session_count = df.select(pl.struct([\"athlete_name\", \"test_date\"]).n_unique()).item()\n",
    "\n",
    "    message = f\"\"\"\n",
    "{stage}:\n",
    "    First CMJ recorded date: {first_date}\n",
    "    Last CMJ recorded date: {last_date}\n",
    "    Count of CMJ repetitions: {rep_count}\n",
    "    Count of athletes: {athlete_count}\n",
    "    Count of sessions: {session_count}\n",
    "------------------------------------------------------\"\"\"\n",
    "\n",
    "    ensure_dir(os.path.dirname(log_path) or \".\")\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(message)\n",
    "\n",
    "\n",
    "def log_message(message: str, log_path: str) -> None:\n",
    "    ensure_dir(os.path.dirname(log_path) or \".\")\n",
    "    with open(log_path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(message)\n",
    "\n",
    "\n",
    "def reset_log(log_path: str) -> None:\n",
    "    ensure_dir(os.path.dirname(log_path) or \".\")\n",
    "    with open(log_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1736857e",
   "metadata": {},
   "source": [
    "## Data pipeline functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9e84392f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_combine(src_path: str, combined_path: str) -> pl.DataFrame:\n",
    "    files = glob.glob(os.path.join(src_path, \"*.csv\"))\n",
    "    df_all = pl.concat([pl.read_csv(f) for f in files], how=\"diagonal_relaxed\")\n",
    "\n",
    "    df_all = df_all.filter(~pl.col(\"athlete_name\").is_in(ATHLETES_TO_DROP))\n",
    "    df_all = df_all.unique(\"id\")\n",
    "    df_all = df_all.drop(COLUMNS_TO_DROP)\n",
    "\n",
    "    df_all = df_all.with_columns(\n",
    "        pl.from_epoch(pl.col(\"timestamp\"), time_unit=\"s\").alias(\"test_datetime\"),\n",
    "        pl.from_epoch(pl.col(\"last_sync_time\"), time_unit=\"s\").alias(\"last_sync_time\"),\n",
    "        (pl.col(\"system_weight_n\") / G_ACC).round(2).alias(\"system_weight_kg\"),\n",
    "    )\n",
    "    df_all = df_all.with_columns(\n",
    "        pl.col(\"test_datetime\").dt.date().alias(\"test_date\")\n",
    "    )\n",
    "\n",
    "    columns = df_all.columns.copy()\n",
    "    columns.append(columns.pop(columns.index(\"last_sync_time\")))\n",
    "    columns.insert(columns.index(\"timestamp\") + 1, columns.pop(columns.index(\"test_datetime\")))\n",
    "    columns.insert(columns.index(\"test_datetime\") + 1, columns.pop(columns.index(\"test_date\")))\n",
    "    df_all = df_all.select(columns)\n",
    "\n",
    "    df_all = df_all.sort(\"test_datetime\")\n",
    "\n",
    "    ensure_dir(os.path.dirname(combined_path) or \".\")\n",
    "    df_all.write_csv(combined_path)\n",
    "    return df_all\n",
    "\n",
    "def filter_cmj(df_all: pl.DataFrame, cmj_test_type: str, pure_cmj_path: str) -> pl.DataFrame:\n",
    "    df_cmj = df_all.filter(pl.col(\"testType_name\") == cmj_test_type)\n",
    "    df_cmj = df_cmj.drop(\"tag_names\")\n",
    "    ensure_dir(os.path.dirname(pure_cmj_path) or \".\")\n",
    "    df_cmj.write_csv(pure_cmj_path)\n",
    "    return df_cmj\n",
    "\n",
    "def add_session_rep_columns(df_cmj: pl.DataFrame) -> pl.DataFrame:\n",
    "    ts_col = \"timestamp\"\n",
    "    df = (\n",
    "        df_cmj\n",
    "        .sort([ts_col, \"athlete_name\"])\n",
    "        .with_columns(\n",
    "            pl.col(\"test_date\").rank(method=\"dense\").over(\"athlete_name\").alias(\"session_number\")\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(ts_col).rank(method=\"dense\").over([\"session_number\", \"athlete_name\"]).alias(\"rep_number\")\n",
    "        )\n",
    "        .with_columns(\n",
    "            pl.col(ts_col).shift(1).over([\"athlete_name\", \"session_number\"]).alias(\"prev_rep_timestamp\")\n",
    "        )\n",
    "        .with_columns(\n",
    "            rest_before_rep_seconds=pl.col(ts_col) - pl.col(\"prev_rep_timestamp\")\n",
    "        )\n",
    "        .drop(\"prev_rep_timestamp\")\n",
    "    )\n",
    "\n",
    "    columns = df.columns.copy()\n",
    "    columns.insert(0, columns.pop(columns.index(\"athlete_name\")))\n",
    "    columns.insert(columns.index(\"test_date\") + 1, columns.pop(columns.index(\"session_number\")))\n",
    "    columns.insert(columns.index(\"session_number\") + 1, columns.pop(columns.index(\"rep_number\")))\n",
    "    columns.insert(columns.index(\"rep_number\") + 1, columns.pop(columns.index(\"rest_before_rep_seconds\")))\n",
    "    return df.select(columns)\n",
    "\n",
    "def add_mrsi_session_stats(df: pl.DataFrame) -> pl.DataFrame:\n",
    "    session_keys = [\"athlete_name\", \"session_number\"]\n",
    "    df = df.with_columns([\n",
    "        pl.col(\"mrsi\").max().round(4).over(session_keys).alias(\"max_mrsi_in_session\"),\n",
    "        pl.col(\"mrsi\").mean().round(4).over(session_keys).alias(\"avg_mrsi_in_session\"),\n",
    "        pl.col(\"mrsi\").sort(descending=True).head(3).mean().round(4).over(session_keys)\n",
    "        .alias(\"avg_3_best_mrsi_in_session\"),\n",
    "    ])\n",
    "\n",
    "    columns = df.columns.copy()\n",
    "    columns.insert(columns.index(\"mrsi\") + 1, columns.pop(columns.index(\"max_mrsi_in_session\")))\n",
    "    columns.insert(columns.index(\"mrsi\") + 2, columns.pop(columns.index(\"avg_mrsi_in_session\")))\n",
    "    columns.insert(columns.index(\"mrsi\") + 3, columns.pop(columns.index(\"avg_3_best_mrsi_in_session\")))\n",
    "    return df.select(columns)\n",
    "\n",
    "def add_within_athlete_zscore_abs(\n",
    "    df: pl.DataFrame,\n",
    "    metric_col: str,\n",
    "    ddof: int = 1,\n",
    ") -> pl.DataFrame:\n",
    "    df_abs = df.with_columns(pl.col(metric_col).abs())\n",
    "    stats = (\n",
    "        df_abs.group_by(\"athlete_name\")\n",
    "        .agg([\n",
    "            pl.col(metric_col).mean().alias(\"m_mean\"),\n",
    "            pl.col(metric_col).std(ddof=ddof).alias(\"m_sd\"),\n",
    "        ])\n",
    "        .with_columns(pl.col(\"m_sd\").replace(0, None).alias(\"m_sd\"))\n",
    "    )\n",
    "    df2 = df_abs.join(stats, on=\"athlete_name\", how=\"left\")\n",
    "    z_expr = (pl.col(metric_col) - pl.col(\"m_mean\")) / pl.col(\"m_sd\")\n",
    "    return df2.with_columns(z_expr.fill_null(0.0).fill_nan(0.0).alias(\"z_score\"))\n",
    "\n",
    "def best_session_ever(df: pl.DataFrame, kpi_col: str) -> pl.DataFrame:\n",
    "    return (\n",
    "        df.with_columns(\n",
    "            pl.col(\"session_number\")\n",
    "            .sort_by(pl.col(kpi_col).abs(), descending=True)\n",
    "            .first()\n",
    "            .over(\"athlete_name\")\n",
    "            .alias(\"best_session_number\")\n",
    "        )\n",
    "        .filter(pl.col(\"session_number\") == pl.col(\"best_session_number\"))\n",
    "        .drop(\"best_session_number\")\n",
    "    )\n",
    "\n",
    "def get_best_reps(df: pl.DataFrame, selector: str) -> pl.DataFrame:\n",
    "    return (\n",
    "        df.with_columns(\n",
    "            pl.col(\"rep_number\")\n",
    "            .sort_by(pl.col(selector).abs(), descending=True)\n",
    "            .first()\n",
    "            .over(\"athlete_name\")\n",
    "            .alias(\"best_rep_number\")\n",
    "        )\n",
    "        .filter(pl.col(\"rep_number\") == pl.col(\"best_rep_number\"))\n",
    "        .drop(\"best_rep_number\")\n",
    "    )\n",
    "\n",
    "def write_best_rep_stats(best_rep_df: pl.DataFrame, out_path: str) -> None:\n",
    "    stats_df = (\n",
    "        best_rep_df\n",
    "        .group_by(\"rep_number\")\n",
    "        .len()\n",
    "        .rename({\"len\": \"count\"})\n",
    "        .sort(\"rep_number\")\n",
    "    )\n",
    "    ensure_dir(os.path.dirname(out_path) or \".\")\n",
    "    stats_df.write_csv(out_path)\n",
    "\n",
    "def filter_outliers(df: pl.DataFrame, col: str, sigma_threshold: int) -> pl.DataFrame:\n",
    "    sd_filter = pl.col(f\"{col}_z_score\").is_between(-1 * sigma_threshold, sigma_threshold, \"none\")\n",
    "    return df.filter(sd_filter)\n",
    "\n",
    "def add_sex_height_from_csv(df: pl.DataFrame, src_file: str) -> pl.DataFrame:\n",
    "    df_sex_height = pl.read_csv(src_file)\n",
    "    df = df.join(\n",
    "        df_sex_height,\n",
    "        on=\"athlete_name\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    if df.filter(pl.col(\"sex\").is_null() | (pl.col(\"sex\") == \"\")).height > 0:\n",
    "        raise Exception (\"There are athletes without assigned sex!\")\n",
    "\n",
    "    if df.filter(pl.col(\"height_cm\").is_null() | (pl.col(\"height_cm\") == 0)).height > 0:\n",
    "        raise Exception (\"There are athletes without height_cm!\")\n",
    "\n",
    "    \n",
    "    columns = df.columns.copy()\n",
    "\n",
    "    columns.insert(columns.index(\"athlete_name\") + 1, columns.pop(columns.index(\"sex\")))\n",
    "    columns.insert(columns.index(\"athlete_name\") + 2, columns.pop(columns.index(\"height_cm\")))\n",
    "\n",
    "    return df.select(columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9a1924",
   "metadata": {},
   "source": [
    "## Plotting functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dd09bbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "CI_COLOR = \"#ff8c00\"\n",
    "MEDIAN_COLOR = \"#b35900\"\n",
    "MEAN_COLOR = \"#d62728\"\n",
    "PARETO_LINE_COLOR = \"#2ca02c\"\n",
    "\n",
    "BOX_WIDTH = 0.25\n",
    "MEAN_X_OFFSET = BOX_WIDTH / 2.0\n",
    "SEED_BOOT = 42\n",
    "SEED_JITTER = 123\n",
    "REP_COLS = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "\n",
    "def set_manuscript_font() -> None:\n",
    "    available = {f.name for f in fm.fontManager.ttflist}\n",
    "    family = (\n",
    "        (\"Times New Roman\" in available and \"Times New Roman\")\n",
    "        or (\"Nimbus Roman\" in available and \"Nimbus Roman\")\n",
    "        or \"serif\"\n",
    "    )\n",
    "\n",
    "    plt.rcParams.update({\n",
    "        \"font.family\": family,\n",
    "        \"font.size\": 12,\n",
    "        \"axes.titlesize\": 11,\n",
    "        \"axes.labelsize\": 12,\n",
    "        \"xtick.labelsize\": 11,\n",
    "        \"ytick.labelsize\": 11,\n",
    "    })\n",
    "\n",
    "\n",
    "def bootstrap_median_ci(values: np.ndarray, B: int = 5000, rng: np.random.Generator | None = None):\n",
    "    values = np.asarray(values, dtype=float)\n",
    "    n = len(values)\n",
    "    rng = rng or np.random.default_rng(SEED_BOOT)\n",
    "\n",
    "    boot = np.empty(B, dtype=float)\n",
    "    for b in range(B):\n",
    "        boot[b] = np.median(rng.choice(values, size=n, replace=True))\n",
    "\n",
    "    med = float(np.median(values))\n",
    "    lo = float(np.percentile(boot, 2.5))\n",
    "    hi = float(np.percentile(boot, 97.5))\n",
    "    return med, lo, hi\n",
    "\n",
    "\n",
    "def add_n_annotation(ax: plt.Axes, n: int) -> None:\n",
    "    ax.text(0.99, 0.02, f\"n={n}\", transform=ax.transAxes, ha=\"right\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "\n",
    "def plot_raincloud(\n",
    "    df_bestday,\n",
    "    title: str,\n",
    "    y_limits: tuple,\n",
    "    out_png: str,\n",
    "    out_csv: str | None = None,\n",
    "    out_stats_csv: str | None = None,\n",
    "    rep_col: str = \"rep_number\",\n",
    "    metric_col: str = \"metric\",\n",
    "    z_col: str = \"z_score\",\n",
    "    y_label: str = \"Within-athlete z-score\",\n",
    ") -> None:\n",
    "    df_plot = (\n",
    "        df_bestday\n",
    "        .with_columns([\n",
    "            pl.col(rep_col).cast(pl.Int64, strict=False).alias(rep_col),\n",
    "            pl.col(z_col).cast(pl.Float64, strict=False).alias(z_col),\n",
    "            pl.col(metric_col).cast(pl.Float64, strict=False).alias(metric_col),\n",
    "        ])\n",
    "        .filter(pl.col(rep_col).is_between(1, 6))\n",
    "        .filter(pl.col(z_col).is_not_null())\n",
    "        .filter(pl.col(metric_col).is_not_null())\n",
    "        .select( TECHNICAL_COLUMNS + [ z_col, metric_col ])\n",
    "    )\n",
    "\n",
    "    z_data_by_rep = [\n",
    "        df_plot.filter(pl.col(rep_col) == r).get_column(z_col).to_numpy()\n",
    "        for r in REP_COLS\n",
    "    ]\n",
    "\n",
    "    raw_data_by_rep = [\n",
    "        df_plot.filter(pl.col(rep_col) == r).get_column(metric_col).to_numpy()\n",
    "        for r in REP_COLS\n",
    "    ]\n",
    "\n",
    "    rng_ci = np.random.default_rng(SEED_BOOT)\n",
    "\n",
    "    counts, means, medians, sds, ci_low, ci_high = [], [], [], [], [], []\n",
    "    for vals in z_data_by_rep:\n",
    "        arr = np.asarray(vals, dtype=float)\n",
    "        counts.append(len(arr))\n",
    "        means.append(float(np.mean(arr)) if len(arr) else np.nan)\n",
    "        medians.append(float(np.median(arr)) if len(arr) else np.nan)\n",
    "        if len(arr) == 0:\n",
    "            sds.append(np.nan)\n",
    "        elif len(arr) == 1:\n",
    "            sds.append(0.0)\n",
    "        else:\n",
    "            sds.append(float(np.std(arr, ddof=1)))\n",
    "        _, lo, hi = bootstrap_median_ci(arr, B=5000, rng=rng_ci)\n",
    "        ci_low.append(lo)\n",
    "        ci_high.append(hi)\n",
    "\n",
    "    means = np.array(means, dtype=float)\n",
    "    ci_low = np.array(ci_low, dtype=float)\n",
    "    ci_high = np.array(ci_high, dtype=float)\n",
    "\n",
    "    raw_counts, raw_means, raw_medians, raw_sds, raw_ci_low, raw_ci_high = [], [], [], [], [], []\n",
    "    for vals in raw_data_by_rep:\n",
    "        arr = np.asarray(vals, dtype=float)\n",
    "        raw_counts.append(len(arr))\n",
    "        raw_means.append(float(np.mean(arr)) if len(arr) else np.nan)\n",
    "        raw_medians.append(float(np.median(arr)) if len(arr) else np.nan)\n",
    "        if len(arr) == 0:\n",
    "            raw_sds.append(np.nan)\n",
    "        elif len(arr) == 1:\n",
    "            raw_sds.append(0.0)\n",
    "        else:\n",
    "            raw_sds.append(float(np.std(arr, ddof=1)))\n",
    "        _, lo, hi = bootstrap_median_ci(arr, B=5000, rng=rng_ci)\n",
    "        raw_ci_low.append(lo)\n",
    "        raw_ci_high.append(hi)\n",
    "\n",
    "    summary_df = pl.DataFrame({\n",
    "        rep_col: REP_COLS,\n",
    "\n",
    "        # z summary\n",
    "        \"count\": counts,\n",
    "        \"z_mean\": means,\n",
    "        \"z_std\": sds,\n",
    "        \"z_median\": medians,\n",
    "        \"z_median_ci_low\": ci_low,\n",
    "        \"z_median_ci_high\": ci_high,\n",
    "\n",
    "        # raw metric summary\n",
    "        f\"src_mean\": raw_means,\n",
    "        f\"src_std\": raw_sds,\n",
    "        f\"src_median\": raw_medians,\n",
    "        f\"src_median_ci_low\": raw_ci_low,\n",
    "        f\"src_median_ci_high\": raw_ci_high,\n",
    "    })\n",
    "\n",
    "    if out_csv:\n",
    "        ensure_dir(os.path.dirname(out_csv) or \".\")\n",
    "        df_plot.write_csv(out_csv)\n",
    "\n",
    "    if out_stats_csv:\n",
    "        ensure_dir(os.path.dirname(out_stats_csv) or \".\")\n",
    "        summary_df.write_csv(out_stats_csv)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7.2, 4.8))\n",
    "    vp = ax.violinplot(\n",
    "        z_data_by_rep,\n",
    "        positions=REP_COLS,\n",
    "        widths=0.85,\n",
    "        showmeans=False,\n",
    "        showmedians=False,\n",
    "        showextrema=False,\n",
    "    )\n",
    "    for body in vp[\"bodies\"]:\n",
    "        body.set_alpha(0.30)\n",
    "        body.set_zorder(1)\n",
    "\n",
    "    rng_points = np.random.default_rng(SEED_JITTER)\n",
    "    x_vals = df_plot.get_column(rep_col).to_numpy().astype(float)\n",
    "    y_vals = df_plot.get_column(z_col).to_numpy().astype(float)\n",
    "    x_jitter = x_vals + rng_points.uniform(-0.12, 0.12, size=len(x_vals))\n",
    "    ax.scatter(x_jitter, y_vals, alpha=0.25, s=10, zorder=2)\n",
    "\n",
    "    ax.boxplot(\n",
    "        z_data_by_rep,\n",
    "        positions=REP_COLS,\n",
    "        widths=BOX_WIDTH,\n",
    "        showfliers=False,\n",
    "        medianprops={\"linewidth\": 1.2, \"color\": MEDIAN_COLOR},\n",
    "        whiskerprops={\"linewidth\": 1.0},\n",
    "        capprops={\"linewidth\": 1.0},\n",
    "        boxprops={\"linewidth\": 1.0},\n",
    "    )\n",
    "\n",
    "    for x, lo, hi in zip(REP_COLS, ci_low, ci_high):\n",
    "        ax.vlines(x, lo, hi, linewidth=0.8, color=CI_COLOR, zorder=4)\n",
    "\n",
    "    mean_x = np.array(REP_COLS, dtype=float) + MEAN_X_OFFSET\n",
    "    ax.scatter(mean_x, means, s=8, color=MEAN_COLOR, zorder=5)\n",
    "\n",
    "    ax.set_title(title, pad=12)\n",
    "    ax.set_xlabel(\"Trial number\")\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_xticks(REP_COLS)\n",
    "    ax.set_xticklabels([str(r) for r in REP_COLS])\n",
    "    ax.axhline(0, linestyle=\"--\", linewidth=1.0, zorder=0)\n",
    "    ax.set_ylim(y_limits)\n",
    "\n",
    "    handles = [\n",
    "        Line2D([0], [0], marker=\"o\", linestyle=\"None\", markersize=4,\n",
    "               markerfacecolor=MEAN_COLOR, markeredgecolor=MEAN_COLOR, label=\"Mean\"),\n",
    "        Line2D([0], [0], color=CI_COLOR, linewidth=1.0, label=\"Median (95% CI)\"),\n",
    "    ]\n",
    "    ax.legend(\n",
    "        handles=handles,\n",
    "        frameon=False,\n",
    "        loc=\"upper right\",\n",
    "        bbox_to_anchor=(0.985, 0.98),\n",
    "        fontsize=9,\n",
    "        handlelength=1.0,\n",
    "        handletextpad=0.4,\n",
    "        borderaxespad=0.0,\n",
    "    )\n",
    "\n",
    "    fig.tight_layout(rect=(0, 0, 1, 0.88))\n",
    "    fig.savefig(out_png, dpi=600, bbox_inches=\"tight\", pad_inches=0.1)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "def count_cum_stats(\n",
    "    best_info,\n",
    "    rep_col: str = \"rep_number\",\n",
    ") -> None:\n",
    "    counts_df = best_info.group_by(rep_col).len().rename({\"len\": \"count\"})\n",
    "    counts_map = dict(\n",
    "        zip(\n",
    "            counts_df.get_column(rep_col).to_list(),\n",
    "            counts_df.get_column(\"count\").to_list(),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    reps = np.array(REP_COLS, dtype=int)\n",
    "    counts = np.array([int(counts_map.get(r, 0)) for r in reps], dtype=int)\n",
    "    total = int(counts.sum())\n",
    "\n",
    "    pct = np.divide(counts, total, out=np.zeros_like(counts, dtype=float), where=total != 0) * 100\n",
    "    cum_pct = np.cumsum(counts) / total * 100 if total else np.zeros_like(counts, dtype=float)\n",
    "\n",
    "    summary_df = pl.DataFrame({\n",
    "            rep_col: reps.tolist(),\n",
    "            \"count\": counts.tolist(),\n",
    "            \"percent\": pct.tolist(),\n",
    "            \"cumulative_percent\": cum_pct.tolist(),\n",
    "        })\n",
    "\n",
    "    return summary_df\n",
    "\n",
    "    \n",
    "def chi_square_g_best_reps(\n",
    "    counts_df: pl.DataFrame,\n",
    "    bonferroni_tests: int = 1,\n",
    "):\n",
    "    observed = counts_df.get_column(\"count\").to_numpy()\n",
    "    df = observed.size - 1\n",
    "    n = observed.sum()\n",
    "    \n",
    "    chi2, p_chi2 = power_divergence(observed, lambda_='pearson') # Chi-Square\n",
    "    v = np.sqrt(chi2 / (n * df)) if n > 0 else np.nan\n",
    "    p_bonf_chi2 = min(p_chi2 * bonferroni_tests, 1.0)\n",
    "    \n",
    "    g, p_g = power_divergence(observed, lambda_=\"log-likelihood\") # G-Test\n",
    "    p_bonf_g = min(p_g * bonferroni_tests, 1.0)\n",
    "\n",
    "    return {\n",
    "        \"N\": n,\n",
    "        \"Chi-square\": chi2,\n",
    "        \"df\": df,\n",
    "        \"p (Chi-square)\": p_chi2,\n",
    "        \"p (Chi-square) Bonferroni\": p_bonf_chi2,\n",
    "        \"Cramer's V\": v,\n",
    "        \"G-test (LRT)\": g,\n",
    "        \"p (G-test)\": p_g,\n",
    "        \"p (G-test) Bonferroni\": p_bonf_g,\n",
    "    }\n",
    "\n",
    "\n",
    "def holm_adjust(p_values: list[float]) -> list[float]:\n",
    "    if not p_values:\n",
    "        return []\n",
    "    m = len(p_values)\n",
    "    order = np.argsort(p_values)\n",
    "    adjusted = [0.0] * m\n",
    "    prev = 0.0\n",
    "    for rank, idx in enumerate(order):\n",
    "        factor = m - rank\n",
    "        adj = p_values[idx] * factor\n",
    "        if adj < prev:\n",
    "            adj = prev\n",
    "        if adj > 1.0:\n",
    "            adj = 1.0\n",
    "        adjusted[idx] = adj\n",
    "        prev = adj\n",
    "    return adjusted\n",
    "\n",
    "\n",
    "def modal_vs_other_from_counts(\n",
    "    counts_df: pl.DataFrame,\n",
    "    metric_label: str,\n",
    "    rep_col: str = \"rep_number\",\n",
    ") -> pl.DataFrame:\n",
    "    counts_map = dict(\n",
    "        zip(\n",
    "            counts_df.get_column(rep_col).to_list(),\n",
    "            counts_df.get_column(\"count\").to_list(),\n",
    "        )\n",
    "    )\n",
    "    counts = [int(counts_map.get(r, 0)) for r in REP_COLS]\n",
    "    n = int(sum(counts))\n",
    "\n",
    "    modal_idx = int(np.argmax(counts))\n",
    "    modal_rep = modal_idx + 1\n",
    "    modal_count = int(counts[modal_idx])\n",
    "\n",
    "    rows = []\n",
    "    p_vals = []\n",
    "\n",
    "    for rep in REP_COLS:\n",
    "        if rep == modal_rep:\n",
    "            continue\n",
    "        comp_count = int(counts[rep - 1])\n",
    "        n_pair = modal_count + comp_count\n",
    "\n",
    "        if n_pair == 0:\n",
    "            p_val = 1.0\n",
    "        else:\n",
    "            p_val = float(binomtest(modal_count, n_pair, 0.5, alternative=\"two-sided\").pvalue)\n",
    "\n",
    "        if modal_count == 0 and comp_count == 0:\n",
    "            or_val = float(\"nan\")\n",
    "            ci_low = float(\"nan\")\n",
    "            ci_high = float(\"nan\")\n",
    "        else:\n",
    "            a = modal_count\n",
    "            b = comp_count\n",
    "            if a == 0 or b == 0:\n",
    "                a += 0.5\n",
    "                b += 0.5\n",
    "            or_val = float(a / b)\n",
    "            se = float(np.sqrt(1.0 / a + 1.0 / b))\n",
    "            log_or = float(np.log(or_val))\n",
    "            ci_low = float(np.exp(log_or - 1.96 * se))\n",
    "            ci_high = float(np.exp(log_or + 1.96 * se))\n",
    "\n",
    "        rows.append({\n",
    "            \"Metric\": metric_label,\n",
    "            \"N\": n,\n",
    "            \"Modal rep\": modal_rep,\n",
    "            \"Compared rep\": rep,\n",
    "            \"Count modal rep\": modal_count,\n",
    "            \"Count compared rep\": comp_count,\n",
    "            \"OR (modal/compared)\": or_val,\n",
    "            \"CI95% low\": ci_low,\n",
    "            \"CI95% high\": ci_high,\n",
    "            \"p (exact binomial, two-sided)\": p_val,\n",
    "            \"Counts (Rep1-Rep6)\": \", \".join(str(c) for c in counts),\n",
    "        })\n",
    "        p_vals.append(p_val)\n",
    "\n",
    "    adjusted = holm_adjust(p_vals)\n",
    "    for row, adj in zip(rows, adjusted):\n",
    "        row[\"p (Holm, within-metric)\"] = adj\n",
    "        row[\"Significant (Holm<0.05)\"] = adj < 0.05\n",
    "\n",
    "    return pl.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264e562d",
   "metadata": {},
   "source": [
    "## Generic plot runner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "04e87fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_metric_plots(\n",
    "    df_all_sessions: pl.DataFrame,\n",
    "    df_best_session: pl.DataFrame,\n",
    "    metric_col: str,\n",
    "    metric_label: str,\n",
    "    out_dir: str,\n",
    "    out_prefix: str,\n",
    ") -> pl.DataFrame:\n",
    "    df_best = df_all_sessions.join(\n",
    "        df_best_session,\n",
    "        on=[\"athlete_name\", \"session_number\"],\n",
    "        how=\"semi\",\n",
    "    )\n",
    "\n",
    "    best_rep_df = get_best_reps(df_best, metric_col)\n",
    "\n",
    "    rep_col = \"rep_number\"\n",
    "\n",
    "    raincloud_summary_df = plot_raincloud(\n",
    "        df_best,\n",
    "        title=f\"CMJ ({metric_label}) â€“ within-athlete z-score distribution by trial\",\n",
    "        y_limits=(-SIGMA_THRESHOLD - 0.25, SIGMA_THRESHOLD + 0.25),\n",
    "        out_png=f\"{out_dir}/{out_prefix}_raincloud.png\",\n",
    "        out_csv=f\"{out_dir}/{out_prefix}_raincloud.csv\",\n",
    "        out_stats_csv=f\"{out_dir}/{out_prefix}_raincloud_stats.csv\",\n",
    "        metric_col=metric_col,\n",
    "        z_col=f\"{metric_col}_z_score\",\n",
    "        rep_col=rep_col,\n",
    "        y_label=\"Within-athlete z-score\",\n",
    "    )\n",
    "\n",
    "    raincloud_summary_df = raincloud_summary_df.with_columns(pl.lit(metric_label).alias(\"metric_label\"))\n",
    "\n",
    "    cum_stats_df = count_cum_stats(\n",
    "        best_rep_df,\n",
    "        rep_col=rep_col,\n",
    "    )\n",
    "\n",
    "    modal_vs_other_df = modal_vs_other_from_counts(\n",
    "        cum_stats_df,\n",
    "        metric_label=metric_label,\n",
    "        rep_col=rep_col,\n",
    "    )\n",
    "\n",
    "    chi2_g_df = pl.DataFrame(chi_square_g_best_reps(\n",
    "        cum_stats_df,\n",
    "        bonferroni_tests=len(METRICS_CONFIG),\n",
    "    ))\n",
    "\n",
    "\n",
    "    chi2_g_df = chi2_g_df.with_columns(\n",
    "            pl.lit(\n",
    "                \", \".join(str(cnt) for cnt in cum_stats_df[\"count\"].to_list()))\n",
    "                .alias(\"Counts (Rep1-Rep6)\"),\n",
    "            pl.lit(metric_label).alias(\"Metric\")\n",
    "        )\n",
    "\n",
    "    ensure_dir(os.path.dirname(out_dir) or \".\")\n",
    "    chi2_g_df.write_csv(f\"{out_dir}/{out_prefix}_chi2.csv\")\n",
    "\n",
    "    summary_df = raincloud_summary_df.join(\n",
    "        cum_stats_df,\n",
    "        on=rep_col,\n",
    "        how=\"inner\",\n",
    "    )\n",
    "\n",
    "    return summary_df, chi2_g_df, modal_vs_other_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7863b66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_raincloud_panel(\n",
    "    image_paths: list[str],\n",
    "    metric_labels: list[str],\n",
    "    out_path: str,\n",
    "    ncols: int = 2,\n",
    "    wspace: float = 0.12,\n",
    "    hspace: float = 0.08,\n",
    ") -> None:\n",
    "    if len(image_paths) != len(metric_labels):\n",
    "        raise ValueError(\"image_paths and metric_labels must have the same length.\")\n",
    "\n",
    "    nrows = int(np.ceil(len(image_paths) / ncols))\n",
    "    fig_height = max(3.5, 4 * nrows)\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(12, fig_height))\n",
    "    axes_flat = np.array(axes).ravel()\n",
    "\n",
    "    for ax, img_path, label in zip(axes_flat, image_paths, metric_labels):\n",
    "        if not os.path.exists(img_path):\n",
    "            raise FileNotFoundError(f\"Missing raincloud plot: {img_path}\")\n",
    "        img = plt.imread(img_path)\n",
    "        ax.imshow(img)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    for ax in axes_flat[len(image_paths):]:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    fig.subplots_adjust(hspace=hspace, wspace=wspace)\n",
    "    fig.tight_layout(rect=(0, 0, 1, 1))\n",
    "    ensure_dir(os.path.dirname(out_path) or \".\")\n",
    "    fig.savefig(out_path, dpi=600, bbox_inches=\"tight\", pad_inches=0.05)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def create_raincloud_panels(\n",
    "    plots_dir: str,\n",
    "    panel_specs: list[tuple],\n",
    "    panel_dir_name: str = \"raincloud_panels\",\n",
    "    default_ncols: int = 2,\n",
    ") -> None:\n",
    "    metric_label_map = dict(METRICS_CONFIG)\n",
    "    panel_dir = os.path.join(plots_dir, panel_dir_name)\n",
    "    ensure_dir(panel_dir)\n",
    "\n",
    "    for spec in panel_specs:\n",
    "        if len(spec) == 2:\n",
    "            panel_name, metrics = spec\n",
    "            ncols = default_ncols\n",
    "        elif len(spec) == 3:\n",
    "            panel_name, metrics, ncols = spec\n",
    "        else:\n",
    "            raise ValueError(\"panel_specs entries must be (name, metrics) or (name, metrics, ncols)\")\n",
    "\n",
    "        image_paths = [\n",
    "            os.path.join(plots_dir, m, f\"CMJ_{m}_raincloud.png\")\n",
    "            for m in metrics\n",
    "        ]\n",
    "        metric_labels = [metric_label_map.get(m, m) for m in metrics]\n",
    "        out_path = os.path.join(panel_dir, f\"{panel_name}_raincloud_panel.png\")\n",
    "        assemble_raincloud_panel(\n",
    "            image_paths=image_paths,\n",
    "            metric_labels=metric_labels,\n",
    "            out_path=out_path,\n",
    "            ncols=ncols,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ee4b29",
   "metadata": {},
   "source": [
    "## Run pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a3cce5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensure_dir(PLOTS_DIR)\n",
    "ensure_dir(STATS_DIR)\n",
    "set_manuscript_font()\n",
    "reset_log(LOG_PATH)\n",
    "\n",
    "df_all = load_and_combine(SRC_PATH, COMBINED_PATH)\n",
    "df_cmj = filter_cmj(df_all, CMJ_TEST_TYPE, PURE_CMJ_PATH)\n",
    "df_cmj_sessions = add_session_rep_columns(df_cmj)\n",
    "\n",
    "df_filtered = df_cmj_sessions.select(TECHNICAL_COLUMNS + METRICS_COLUMNS)\n",
    "\n",
    "log_stats(\"Initially\", df_filtered, LOG_PATH)\n",
    "\n",
    "df_filtered = (\n",
    "    df_filtered\n",
    "    .with_columns(\n",
    "        pl.col(\"rep_number\").count().over([\"athlete_name\", \"session_number\"]).alias(\"rep_numbers_in_session\")\n",
    "    )\n",
    "    .filter(pl.col(\"rep_numbers_in_session\") >= MIN_REPS_IN_FAM_SESSION)\n",
    ")\n",
    "\n",
    "log_stats(\"Sessions with at least 3 repetitions\", df_filtered, LOG_PATH)\n",
    "\n",
    "df_filtered = df_filtered.filter(pl.col(\"session_number\") > MIN_FAMILIARIZATION_DAYS)\n",
    "\n",
    "log_stats(\"One familiarization session removed from dataset\", df_filtered, LOG_PATH)\n",
    "\n",
    "df_filtered = df_filtered.filter(pl.col(\"rep_numbers_in_session\") >= MIN_REPS_IN_VALID_SESSION)\n",
    "\n",
    "log_stats(\"Correct sessions with at least 6 repetitions\", df_filtered, LOG_PATH)\n",
    "\n",
    "df_filtered = df_filtered.filter(pl.col(\"rep_number\") <= KEEP_FIRST_N)\n",
    "\n",
    "log_stats(\"Correct tests protocols - removed repetitions above 6th\", df_filtered, LOG_PATH)\n",
    "\n",
    "df_filtered = df_filtered.join(\n",
    "    df_filtered\n",
    "    .filter(\n",
    "        (pl.col(\"rep_number\") == 4) &\n",
    "        (pl.col(\"rest_before_rep_seconds\") >= REST_THRESHOLD_SEC)\n",
    "    )\n",
    "    .select([\"athlete_name\", \"session_number\"])\n",
    "    .unique(),\n",
    "    on=[\"athlete_name\", \"session_number\"],\n",
    "    how=\"semi\",\n",
    ")\n",
    "\n",
    "log_stats(\"Correct tests protocols with at least 30 seconds of rest\", df_filtered, LOG_PATH)\n",
    "\n",
    "df_filtered = add_mrsi_session_stats(df_filtered)\n",
    "\n",
    "df_filtered = add_sex_height_from_csv(df_filtered, \"data/athletes.csv\")\n",
    "\n",
    "df_filtered = df_filtered.drop(\"rep_numbers_in_session\")\n",
    "\n",
    "# Calcualte z-scores per rep\n",
    "df_filtered = df_filtered.with_columns(\n",
    "    [\n",
    "        (\n",
    "            (pl.col(c).abs() - pl.col(c).abs().mean().over(\"athlete_name\"))\n",
    "            / pl.col(c).abs().std(ddof=1).over(\"athlete_name\")\n",
    "        ).alias(f\"{c}_z_score\")\n",
    "        for c in METRICS_COLUMNS\n",
    "])\n",
    "\n",
    "df_filtered.write_csv(\"data/filtered_data.csv\")\n",
    "\n",
    "mean_n = df_filtered.select(pl.col(\"system_weight_n\").mean().round(2)).item()\n",
    "std_n = df_filtered.select(pl.col(\"system_weight_n\").std(ddof=0).round(2)).item()\n",
    "mean_kg = df_filtered.select(pl.col(\"system_weight_kg\").mean().round(2)).item()\n",
    "std_kg = df_filtered.select(pl.col(\"system_weight_kg\").std(ddof=0).round(2)).item()\n",
    "mean_height = df_filtered.select(pl.col(\"height_cm\").mean().round(2)).item()\n",
    "std_height = df_filtered.select(pl.col(\"height_cm\").std(ddof=0).round(2)).item()\n",
    "males_cnt = df_filtered.filter(pl.col(\"sex\") == \"M\").select(\"athlete_name\").unique().height\n",
    "females_cnt = df_filtered.filter(pl.col(\"sex\") == \"F\").select(\"athlete_name\").unique().height\n",
    "\n",
    "log_message(f\"\"\"\n",
    "Demographics of filtered dataset:\n",
    "    Average weight in N: {mean_n},\n",
    "    STD of system weight in N: {std_n},\n",
    "\n",
    "    Average weight in kg: {mean_kg},\n",
    "    STD of weight in kg: {std_kg},\n",
    "    \n",
    "    Average height in cm: {mean_height},\n",
    "    STD of height in cm: {std_height},\n",
    "    \n",
    "    Males count: {males_cnt},\n",
    "    Females count: {females_cnt}\n",
    "\"\"\",\n",
    "LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea5c2bd",
   "metadata": {},
   "source": [
    "## Choose best session and generate plots for a metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3b6d78e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECALCULATE_Z_SCORE = False\n",
    "\n",
    "# Choose best session based on max mRSI and generate plots for each metric\n",
    "df_best_session = best_session_ever(df_filtered, \"max_mrsi_in_session\")\n",
    "\n",
    "df_best_session.write_csv(\"data/best_session_per_athlete.csv\")\n",
    "\n",
    "# Initial schemas with first columns - others will be added in concat\n",
    "summary_df = pl.DataFrame(schema={\"metric_label\": pl.String})\n",
    "chi2_g_df = pl.DataFrame(schema={\n",
    "    \"Metric\": pl.String,\n",
    "    \"N\": pl.String,\n",
    "    \"Counts (Rep1-Rep6)\": pl.String\n",
    "})\n",
    "\n",
    "\n",
    "modal_vs_other_df = pl.DataFrame(schema={\n",
    "    \"Metric\": pl.String,\n",
    "    \"N\": pl.Int64,\n",
    "    \"Modal rep\": pl.Int64,\n",
    "    \"Compared rep\": pl.Int64,\n",
    "    \"Count modal rep\": pl.Int64,\n",
    "    \"Count compared rep\": pl.Int64,\n",
    "    \"OR (modal/compared)\": pl.Float64,\n",
    "    \"CI95% low\": pl.Float64,\n",
    "    \"CI95% high\": pl.Float64,\n",
    "    \"p (exact binomial, two-sided)\": pl.Float64,\n",
    "    \"p (Holm, within-metric)\": pl.Float64,\n",
    "    \"Significant (Holm<0.05)\": pl.Boolean,\n",
    "    \"Counts (Rep1-Rep6)\": pl.String,\n",
    "})\n",
    "\n",
    "outliers = []\n",
    "\n",
    "for metric_col, metric_label in METRICS_CONFIG:\n",
    "    metric_dir = f\"{PLOTS_DIR}/{metric_col}\"\n",
    "    ensure_dir(metric_dir)\n",
    "\n",
    "    cnt_w_outliers = df_filtered.height\n",
    "    df_wo_outliers = filter_outliers(df_filtered, metric_col, SIGMA_THRESHOLD)\n",
    "    cnt_wo_outliers = df_wo_outliers.height\n",
    "\n",
    "    if RECALCULATE_Z_SCORE:\n",
    "        df_wo_outliers = df_wo_outliers.with_columns(\n",
    "            [\n",
    "                (\n",
    "                    (pl.col(c).abs() - pl.col(c).abs().mean().over(\"athlete_name\"))\n",
    "                    / pl.col(c).abs().std(ddof=1).over(\"athlete_name\")\n",
    "                ).alias(f\"{c}_z_score\")\n",
    "                for c in METRICS_COLUMNS\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    outliers.append({\n",
    "        \"Metric\": metric_label,\n",
    "        \"N (before outlier removal)\": cnt_w_outliers,\n",
    "        \"N (after >4 SD removal)\": cnt_wo_outliers,\n",
    "        \"% Data Loss\": (cnt_w_outliers - cnt_wo_outliers) / cnt_w_outliers * 100,\n",
    "    })\n",
    "\n",
    "    new_summary_df, new_chi2_g_df, new_modal_vs_other_df = generate_metric_plots(\n",
    "        df_all_sessions=df_wo_outliers,\n",
    "        df_best_session=df_best_session,\n",
    "        metric_col=metric_col,\n",
    "        metric_label=metric_label,\n",
    "        out_dir=metric_dir,\n",
    "        out_prefix=f\"CMJ_{metric_col}\",\n",
    "    )\n",
    "\n",
    "    summary_df = pl.concat([summary_df, new_summary_df], how=\"diagonal_relaxed\")\n",
    "\n",
    "    chi2_g_df = pl.concat([chi2_g_df, new_chi2_g_df], how=\"diagonal_relaxed\")\n",
    "\n",
    "    modal_vs_other_df = pl.concat([modal_vs_other_df, new_modal_vs_other_df], how=\"diagonal_relaxed\")\n",
    "\n",
    "summary_df = summary_df.rename({\"count_right\": \"reps_count\"})\n",
    "summary_df.write_csv(f\"{DATA_DIR}/all_summary.csv\")\n",
    "chi2_g_df.write_csv(f\"{DATA_DIR}/chi2_g_summary.csv\")\n",
    "modal_vs_other_df.write_csv(f\"{DATA_DIR}/modal_vs_other.csv\")\n",
    "\n",
    "pl.DataFrame(outliers).write_csv(f\"{DATA_DIR}/outliers_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0ac65ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_specs = [\n",
    "    (\"all_metrics\", [\n",
    "        \"jump_height_m\",\n",
    "        \"mrsi\",\n",
    "        \"stiffness_n_m\",\n",
    "        \"avg_relative_braking_force\",\n",
    "        \"avg_relative_braking_power_w_kg\",\n",
    "        \"avg_relative_propulsive_force\",\n",
    "        \"avg_relative_propulsive_power_w_kg\",\n",
    "    ], 2),\n",
    "]\n",
    "\n",
    "create_raincloud_panels(\n",
    "    plots_dir=PLOTS_DIR,\n",
    "    panel_specs=panel_specs,\n",
    "    default_ncols=2,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_hawkin (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
